{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "files = [\"topic-0.txt\", \"topic-1.txt\", \"topic-2.txt\", \"topic-3.txt\", \"topic-4.txt\"]\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "# Read in the vocab into an array\n",
    "vocabMap = []\n",
    "with open(\"vocab.txt\") as file:\n",
    "\tfor line in file:\n",
    "\t\tfields = line.strip().split(\"\\t\")\n",
    "\t\tvocabMap.append(fields[1])\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "# Generate Ck based on Lk-1\n",
    "def apriori_gen(Lkminus1):\n",
    "\tCk = OrderedDict()\n",
    "\tfor i in range(0, len(Lkminus1)):\n",
    "\t\tl1 = list(Lkminus1.items())[i][0]\n",
    "\t\tfor j in range(i+1, len(Lkminus1)):\n",
    "\t\t\tl2 = list(Lkminus1.items())[j][0]\n",
    "\n",
    "\t\t\tpos1 = l1.rfind(\" \")\n",
    "\t\t\tpos2 = l2.rfind(\" \")\n",
    "\n",
    "\t\t\tif pos1 == -1 and pos2 == -1:\n",
    "\t\t\t\tCk[ l1 + \" \" + l2 ] = 0\n",
    "\t\t\telse:\n",
    "\t\t\t\tif l1[0:pos1] == l2[0:pos2]:\n",
    "\t\t\t\t\tc = l1 + \" \" + l2[pos2+1:]\n",
    "\t\t\t\t\tif not has_infrequent_subset(c, Lkminus1):\n",
    "\t\t\t\t\t\tCk[c] = 0\n",
    "\n",
    "\treturn Ck\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "# Check whether a candidate k-itemset has an infrequent (k-1)-itemset\n",
    "def has_infrequent_subset(c, Lkminus1):\n",
    "\tfields = c.split(\" \")\n",
    "\n",
    "\tfor i in range( 0, len(fields)-1 ):\n",
    "\t\tsubset = \"\"\n",
    "\t\tfor j in range( 0, len(fields)-1 ):\n",
    "\t\t\tif i != j:\n",
    "\t\t\t\tsubset += fields[j] + \" \"\n",
    "\t\tsubset += fields[ len(fields) - 1 ]\n",
    "\t\tif subset not in Lkminus1:\n",
    "\t\t\treturn True\n",
    "\treturn False\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "# Main function\n",
    "\n",
    "for fileN in range(0, len(files)):\n",
    "\tfileName = files[fileN]\n",
    "\twith open(fileName) as file:\n",
    "\t\tnumOfTransactions = 0\n",
    "\t\tfreqItemset = OrderedDict()\n",
    "\n",
    "\t\tiCount = [0] * len(vocabMap)\n",
    "\t\tfor line in file:\n",
    "\t\t\tnumOfTransactions += 1\n",
    "\t\t\tfields = [int(n) for n in line.strip().split(\" \")]\n",
    "\t\t\tfor field in fields:\n",
    "\t\t\t\tiCount[field] += 1\n",
    "\n",
    "\t\t# determine min_sup\n",
    "\t\tmin_sup = int( math.ceil( numOfTransactions * 0.01 ) )\n",
    "\n",
    "\t\t# determine L1\n",
    "\t\tL = OrderedDict()\n",
    "\t\tfor i in range( 0, len(iCount) ):\n",
    "\t\t\tif iCount[i] >= min_sup:\n",
    "\t\t\t\tL[ str(i) ] = iCount[i]\n",
    "\t\tfreqItemset.update(L)\n",
    "\n",
    "\t\t# determine L2, L3, ...\n",
    "\t\twhile len(L) != 0:\n",
    "\t\t\tCk = apriori_gen(L)\n",
    "\t\t\tif len(Ck) == 0:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t\tfile.seek(0)\n",
    "\t\t\tfor line in file: # iterate through transaction in db\n",
    "\t\t\t\ttFields = [ int(n) for n in line.strip().split(\" \") ]\n",
    "\n",
    "\t\t\t\tk = len( list(Ck.items())[0][0].split(\" \") )\n",
    "\n",
    "\t\t\t\tfor w in itertools.combinations(tFields, k):\n",
    "\t\t\t\t\tc = \"\"\n",
    "\t\t\t\t\tfor subW in sorted(w):\n",
    "\t\t\t\t\t\tc += str(subW) + \" \"\n",
    "\t\t\t\t\t\tif c.strip() in Ck:\n",
    "\t\t\t\t\t\t\tCk[ c.strip() ] += 1\n",
    "\n",
    "\t\t\tL = OrderedDict()\n",
    "\t\t\tfor i in range( 0, len(Ck) ):\n",
    "\t\t\t\tif list(Ck.items())[i][1] >= min_sup:\n",
    "\t\t\t\t\tL[ list(Ck.items())[i][0] ] = list(Ck.items())[i][1]\n",
    "\n",
    "\t\t\tfreqItemset.update(L)\n",
    "\n",
    "\t\t# write the frequent itemsets into the pattern files\n",
    "\t\tfN = \"pattern-\" + str(fileN) + \".txt\"\n",
    "\t\tf = open(\"patterns/\" + fN, \"w\")\n",
    "\t\tfor key, value in sorted(list(freqItemset.items()), key=lambda k_v: (k_v[1],k_v[0]), reverse=True):\n",
    "\t\t\tf.write( str(value) )\n",
    "\t\t\tline = \"\"\n",
    "\t\t\tfields = key.split(\" \")\n",
    "\t\t\tfor field in fields:\n",
    "\t\t\t\tline += vocabMap[int(field)] + \" \"\n",
    "\t\t\tf.write( \"\\t\" + line.strip() + \"\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
